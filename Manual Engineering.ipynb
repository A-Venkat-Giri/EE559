{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f33d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, accuracy_score, log_loss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from scipy.stats import chi2_contingency, f_oneway\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import KFold, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9357dd7b",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7a1fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('Mushroom_datasets/mushroom_train.csv')\n",
    "data_test = pd.read_csv('Mushroom_datasets/mushroom_test.csv')\n",
    "final_accuracy = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002e20ea",
   "metadata": {},
   "source": [
    "# Trival System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f912f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = data_train.shape[0]\n",
    "N1 = data_train[data_train['class']=='p'].shape[0]\n",
    "N2 = data_train[data_train['class']=='e'].shape[0]\n",
    "N_test = data_test['class'].shape[0]\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(N_test):\n",
    "    if random.random() < N1/N:\n",
    "        y_pred.append('p')\n",
    "    else:\n",
    "        y_pred.append('e')\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(data_test['class'], y_pred)\n",
    "print(\"Accuracy of test dataset is\", accuracy*100, \"%\")\n",
    "final_accuracy['Trival System'] = accuracy*100\n",
    "\n",
    "f_score = f1_score(data_test['class'], y_pred, pos_label='e')\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7cc0e4",
   "metadata": {},
   "source": [
    "# One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139222ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data_train.columns if data_train[col].dtype == 'object']\n",
    "for i in features:\n",
    "    print(\"Unique values of\", i, ':', data_train[i].unique())\n",
    "\n",
    "le = LabelEncoder()\n",
    "features.remove('class')\n",
    "temp_train = pd.get_dummies(data_train, columns=features)\n",
    "temp_test = pd.get_dummies(data_test, columns=features)\n",
    "temp_train['class'] = le.fit_transform(temp_train['class']) \n",
    "temp_test['class'] = le.fit_transform(temp_test['class']) \n",
    "print()\n",
    "print(\"Extra features added =\", temp_train.shape[1]-data_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f985fd1",
   "metadata": {},
   "source": [
    "### Spliting dataset into train and test set and perfoming standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca0cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [col for col in temp_train.select_dtypes(include='float64')]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "temp_train[temp] = scaler.fit_transform(temp_train[temp])\n",
    "X = temp_train.drop('class', axis=1)\n",
    "y = temp_train['class']\n",
    "\n",
    "temp_test[temp] = scaler.fit_transform(temp_test[temp])\n",
    "X_t = temp_test.drop('class', axis=1)\n",
    "y_t = temp_test['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490e59a3",
   "metadata": {},
   "source": [
    "# BaseLine System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f733edab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_means = X.groupby(temp_train['class']).mean()\n",
    "y_pred = []\n",
    "for i in range(len(X_t)):\n",
    "    distances = []\n",
    "    for j in range(len(class_means)):\n",
    "        distances.append(euclidean(X_t.iloc[i], class_means.iloc[j]))\n",
    "    \n",
    "    y_pred.append(distances.index(min(distances)))\n",
    "    \n",
    "accuracy = accuracy_score(y_t, y_pred)\n",
    "print(\"Accuracy of test dataset:\", accuracy*100, \"%\")\n",
    "final_accuracy['Baseline System'] = accuracy*100\n",
    "\n",
    "f_score = f1_score(y_t, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d78008c",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b80e2",
   "metadata": {},
   "source": [
    "### Removing features based on correlations w.r.t class column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45ba645",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train_corr = temp_train[temp_train.columns[1:]].corr(method='pearson')['class'][:]\n",
    "\n",
    "print(\"Fetaures whose correlations are more than 10%\")\n",
    "print()\n",
    "print(\"Features            Correlation\")\n",
    "print()\n",
    "temp_train_corr.drop(temp_train_corr[(temp_train_corr.values > -0.1 ) & (temp_train_corr.values < 0.1)].index, inplace=True)\n",
    "print(temp_train_corr)\n",
    "\n",
    "new_features = temp_train.columns[~temp_train.columns.isin(temp_train_corr.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb32f56d",
   "metadata": {},
   "source": [
    "### Spliting dataset into train and test set and perfoming standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7b82ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train = temp_train.drop(new_features, axis=1)\n",
    "temp_test = temp_test.drop(new_features, axis=1)\n",
    "\n",
    "X_train = temp_train.drop('class', axis=1)\n",
    "y_train = temp_train['class']\n",
    "\n",
    "X_test = temp_test.drop('class', axis=1)\n",
    "y_test = temp_test['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38785af4",
   "metadata": {},
   "source": [
    "# Models with cross validation (k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7f8c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = 10\n",
    "X, X_val, y, y_val = train_test_split(X_train, y_train, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a14f9e4",
   "metadata": {},
   "source": [
    "## 1) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3815a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits, shuffle=True)\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "acc = 0\n",
    "\n",
    "for i,j in kfold.split(X_train):\n",
    "    train_x, val_x = X_train.iloc[i], X_train.iloc[j]\n",
    "    train_y, val_y = y_train.iloc[i], y_train.iloc[j]\n",
    "    \n",
    "    lr = LogisticRegression(max_iter = 10000).fit(train_x, train_y)\n",
    "    predict_train = lr.predict(train_x)\n",
    "    train_accuracy.append(accuracy_score(predict_train, train_y))\n",
    "    \n",
    "    predict_val = lr.predict(val_x)\n",
    "    val_accuracy.append(accuracy_score(predict_val, val_y))\n",
    "    \n",
    "    if val_accuracy[-1] > acc:\n",
    "        acc = val_accuracy[-1]\n",
    "        update = lr\n",
    "        \n",
    "plt.plot(range(1, splits+1), np.array(train_accuracy)*100, label=\"Train dataset\")\n",
    "plt.plot(range(1, splits+1), np.array(val_accuracy)*100, label=\"Val dataset\")\n",
    "plt.title(\"Logistic Regression\")\n",
    "plt.xlabel('KFold Splits')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a150ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = update.predict(X_test)\n",
    "final_accuracy['LR'] = accuracy_score(y_pred, y_test)*100\n",
    "print(\"Accuracy of test dataset:\", final_accuracy['LR'], \"%\")\n",
    "\n",
    "f_score = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82af8c34",
   "metadata": {},
   "source": [
    "## 2) Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101485f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear', C=0.5).fit(X, y)\n",
    "y_pred = svm.predict(X_val)\n",
    "print(accuracy_score(y_pred, y_val))\n",
    "\n",
    "f_score = f1_score(y_val, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424280e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='rbf', C=0.5, gamma = 3).fit(X, y)\n",
    "y_pred = svm.predict(X_val)\n",
    "print(accuracy_score(y_pred, y_val))\n",
    "\n",
    "f_score = f1_score(y_val, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb795195",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='rbf', C=3, gamma = 10).fit(X, y)\n",
    "y_pred = svm.predict(X_val)\n",
    "print(accuracy_score(y_pred, y_val))\n",
    "\n",
    "f_score = f1_score(y_val, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c5f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits, shuffle=True)\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "acc = 0\n",
    "\n",
    "for i,j in kfold.split(X_train):\n",
    "    train_x, val_x = X_train.iloc[i], X_train.iloc[j]\n",
    "    train_y, val_y = y_train.iloc[i], y_train.iloc[j]\n",
    "    \n",
    "    svm = SVC(kernel='rbf', C=3, gamma = 10).fit(train_x, train_y)\n",
    "    predict_train = svm.predict(train_x)\n",
    "    train_accuracy.append(accuracy_score(predict_train, train_y))\n",
    "    \n",
    "    predict_val = svm.predict(val_x)\n",
    "    val_accuracy.append(accuracy_score(predict_val, val_y))\n",
    "    \n",
    "    if val_accuracy[-1] > acc:\n",
    "        acc = val_accuracy[-1]\n",
    "        update = svm\n",
    "        \n",
    "plt.plot(range(1, splits+1), np.array(train_accuracy)*100, label=\"Train dataset\")\n",
    "plt.plot(range(1, splits+1), np.array(val_accuracy)*100, label=\"Val dataset\")\n",
    "plt.title(\"Support Vector Machine\")\n",
    "plt.xlabel('KFold Splits')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5944a0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = update.predict(X_test)\n",
    "final_accuracy['SVM'] = accuracy_score(y_pred, y_test)*100\n",
    "print(\"Accuracy of test dataset:\", final_accuracy['SVM'], \"%\")\n",
    "\n",
    "f_score = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48518430",
   "metadata": {},
   "source": [
    "## 3) Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits, shuffle=True)\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "acc = 0\n",
    "\n",
    "for i,j in kfold.split(X_train):\n",
    "    train_x, val_x = X_train.iloc[i], X_train.iloc[j]\n",
    "    train_y, val_y = y_train.iloc[i], y_train.iloc[j]\n",
    "    \n",
    "    nb = GaussianNB().fit(train_x, train_y)\n",
    "    predict_train = nb.predict(train_x)\n",
    "    train_accuracy.append(accuracy_score(predict_train, train_y))\n",
    "    \n",
    "    predict_val = nb.predict(val_x)\n",
    "    val_accuracy.append(accuracy_score(predict_val, val_y))\n",
    "    \n",
    "    if val_accuracy[-1] > acc:\n",
    "        acc = val_accuracy[-1]\n",
    "        update = nb\n",
    "\n",
    "plt.plot(range(1, splits+1), np.array(train_accuracy)*100, label=\"Train dataset\")\n",
    "plt.plot(range(1, splits+1), np.array(val_accuracy)*100, label=\"Val dataset\")\n",
    "plt.title(\"Naive Bayes\")\n",
    "plt.xlabel('KFold Splits')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aa1655",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = update.predict(X_test)\n",
    "final_accuracy['Naive Bayes'] = accuracy_score(y_pred, y_test)*100\n",
    "print(\"Accuracy of test dataset:\", final_accuracy['Naive Bayes'], \"%\")\n",
    "\n",
    "f_score = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9424c769",
   "metadata": {},
   "source": [
    "## 4) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf3eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits, shuffle=True)\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "acc = 0\n",
    "\n",
    "for i,j in kfold.split(X_train):\n",
    "    train_x, val_x = X_train.iloc[i], X_train.iloc[j]\n",
    "    train_y, val_y = y_train.iloc[i], y_train.iloc[j]\n",
    "    \n",
    "    rfm = RandomForestClassifier(n_estimators=100, random_state=0).fit(train_x, train_y)\n",
    "    predict_train = rfm.predict(train_x)\n",
    "    train_accuracy.append(accuracy_score(predict_train, train_y))\n",
    "    \n",
    "    predict_val = rfm.predict(val_x)\n",
    "    val_accuracy.append(accuracy_score(predict_val, val_y))\n",
    "    \n",
    "    if val_accuracy[-1] > acc:\n",
    "        acc = val_accuracy[-1]\n",
    "        update = rfm\n",
    "        \n",
    "plt.plot(range(1, splits+1), np.array(train_accuracy)*100, label=\"Train dataset\")\n",
    "plt.plot(range(1, splits+1), np.array(val_accuracy)*100, label=\"Val dataset\")\n",
    "plt.title(\"Random Forest\")\n",
    "plt.xlabel('KFold Splits')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f0cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = update.predict(X_test)\n",
    "final_accuracy['Random Forest'] = accuracy_score(y_pred, y_test)*100\n",
    "print(\"Accuracy of test dataset:\", final_accuracy['Random Forest'], \"%\")\n",
    "\n",
    "f_score = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e61392b",
   "metadata": {},
   "source": [
    "## 5) XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e870a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X, label=y)\n",
    "params = {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 3, 'eta': 0.1, 'gamma': 1, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
    "num_rounds = 100\n",
    "\n",
    "xgb_model = xgb.train(params, dtrain, num_rounds)\n",
    "dtest = xgb.DMatrix(X_val, label=y_val)\n",
    "predict = xgb_model.predict(dtest)\n",
    "y_pred = [round(y) for y in predict]\n",
    "print(accuracy_score(y_pred, y_val))\n",
    "\n",
    "f_score = f1_score(y_val, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be960f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X, label=y)\n",
    "params = {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 8, 'eta': 0.5, 'gamma': 3, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
    "num_rounds = 100\n",
    "\n",
    "xgb_model = xgb.train(params, dtrain, num_rounds)\n",
    "dtest = xgb.DMatrix(X_val, label=y_val)\n",
    "predict = xgb_model.predict(dtest)\n",
    "y_pred = [round(y) for y in predict]\n",
    "print(accuracy_score(y_pred, y_val))\n",
    "\n",
    "f_score = f1_score(y_val, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aab3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X, label=y)\n",
    "params = {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 15, 'eta': 0.8, 'gamma': 7, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
    "num_rounds = 100\n",
    "\n",
    "xgb_model = xgb.train(params, dtrain, num_rounds)\n",
    "dtest = xgb.DMatrix(X_val, label=y_val)\n",
    "predict = xgb_model.predict(dtest)\n",
    "y_pred = [round(y) for y in predict]\n",
    "print(accuracy_score(y_pred, y_val))\n",
    "\n",
    "f_score = f1_score(y_val, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62574a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits, shuffle=True)\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "acc = 0\n",
    "\n",
    "for i,j in kfold.split(X_train):\n",
    "    train_x, val_x = X_train.iloc[i], X_train.iloc[j]\n",
    "    train_y, val_y = y_train.iloc[i], y_train.iloc[j]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "    dval = xgb.DMatrix(val_x, label=val_y)\n",
    "    params = {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 8, 'eta': 0.5, 'gamma': 3, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
    "    num_rounds = 100\n",
    "    \n",
    "    xgb_model = xgb.train(params, dtrain, num_rounds)\n",
    "    y_pred_train = xgb_model.predict(dtrain)\n",
    "    y_pred_train_binary = [round(y) for y in y_pred_train]\n",
    "    train_accuracy.append(accuracy_score(y_pred_train_binary, train_y))\n",
    "    \n",
    "    y_pred_test = xgb_model.predict(dval)\n",
    "    y_pred_test_binary = [round(y) for y in y_pred_test]\n",
    "    val_accuracy.append(accuracy_score(y_pred_test_binary, val_y))\n",
    "    \n",
    "    if val_accuracy[-1] > acc:\n",
    "        acc = val_accuracy[-1]\n",
    "        update = xgb_model\n",
    "        \n",
    "plt.plot(range(1, splits+1), np.array(train_accuracy)*100, label=\"Train dataset\")\n",
    "plt.plot(range(1, splits+1), np.array(val_accuracy)*100, label=\"Val dataset\")\n",
    "plt.title(\"XgBoost\")\n",
    "plt.xlabel('KFold Splits')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2486b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "predict = update.predict(dtest)\n",
    "y_pred = [round(y) for y in predict]\n",
    "final_accuracy['XgBoost'] = accuracy_score(y_pred, y_test)*100\n",
    "print(\"Accuracy of test dataset:\", final_accuracy['XgBoost'], \"%\")\n",
    "\n",
    "f_score = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b75b4f",
   "metadata": {},
   "source": [
    "## 6) Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82285e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', alpha=0.0001, learning_rate_init=0.001, max_iter=10000, early_stopping=False) \n",
    "mlp.fit(X, y)\n",
    "\n",
    "y_pred = mlp.predict(X_val)\n",
    "print(accuracy_score(y_pred, y_val))\n",
    "\n",
    "f_score = f1_score(y_val, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd04c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='logistic', solver='sgd', alpha=0.001, learning_rate_init=0.01, max_iter=10000, early_stopping=False) \n",
    "mlp.fit(X, y)\n",
    "\n",
    "y_pred = mlp.predict(X_val)\n",
    "print(accuracy_score(y_pred, y_val))\n",
    "\n",
    "f_score = f1_score(y_val, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1103aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='tanh', solver='adam', alpha=0.01, learning_rate_init=0.5, max_iter=10000, early_stopping=False) \n",
    "mlp.fit(X, y)\n",
    "\n",
    "y_pred = mlp.predict(X_val)\n",
    "print(accuracy_score(y_pred, y_val))\n",
    "\n",
    "f_score = f1_score(y_val, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a2dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits, shuffle=True)\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "acc = 0\n",
    "\n",
    "for i,j in kfold.split(X_train):\n",
    "    train_x, val_x = X_train.iloc[i], X_train.iloc[j]\n",
    "    train_y, val_y = y_train.iloc[i], y_train.iloc[j]\n",
    "    \n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', alpha=0.0001, learning_rate_init=0.001, max_iter=10000, early_stopping=False) \n",
    "    mlp.fit(train_x, train_y)\n",
    "    predict_train = mlp.predict(train_x)\n",
    "    train_accuracy.append(accuracy_score(predict_train, train_y))\n",
    "    \n",
    "    predict_val = mlp.predict(val_x)\n",
    "    val_accuracy.append(accuracy_score(predict_val, val_y))\n",
    "    \n",
    "    if val_accuracy[-1] > acc:\n",
    "        acc = val_accuracy[-1]\n",
    "        update = mlp\n",
    "        \n",
    "plt.plot(range(1, splits+1), np.array(train_accuracy)*100, label=\"Train dataset\")\n",
    "plt.plot(range(1, splits+1), np.array(val_accuracy)*100, label=\"Val dataset\")\n",
    "plt.title(\"Multi Layer Perceptron\")\n",
    "plt.xlabel('KFold Splits')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f16499",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = update.predict(X_test)\n",
    "final_accuracy['MLP'] = accuracy_score(y_pred, y_test)*100\n",
    "print(\"Accuracy of test dataset:\", final_accuracy['MLP'], \"%\")\n",
    "\n",
    "f_score = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf90493",
   "metadata": {},
   "source": [
    "# Final accuracies for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c986d336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = list(final_accuracy.keys())\n",
    "models = list(final_accuracy.values())\n",
    "plt.xticks(rotation = 45, ha='right')\n",
    "\n",
    "bars = plt.bar(accuracy, models)\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x()+bar.get_width()/2, height, '{:.3f}'.format(height), ha='center', va='bottom')\n",
    "    \n",
    "plt.title(\"Model Accuracies for Reduced Feature Engineering\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1632e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = max(final_accuracy, key=final_accuracy.get)\n",
    "best_accuracy = final_accuracy[best_model]\n",
    "print(f\"Best model is {best_model} with accuracy {best_accuracy} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
