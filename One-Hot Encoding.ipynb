{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f33d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, accuracy_score, log_loss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from scipy.stats import chi2_contingency, f_oneway\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import KFold, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9357dd7b",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7a1fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('Mushroom_datasets/mushroom_train.csv')\n",
    "data_test = pd.read_csv('Mushroom_datasets/mushroom_test.csv')\n",
    "final_accuracy = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002e20ea",
   "metadata": {},
   "source": [
    "# Trival System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f912f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = data_train.shape[0]\n",
    "N1 = data_train[data_train['class']=='p'].shape[0]\n",
    "N2 = data_train[data_train['class']=='e'].shape[0]\n",
    "N_test = data_test['class'].shape[0]\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(N_test):\n",
    "    if random.random() < N1/N:\n",
    "        y_pred.append('p')\n",
    "    else:\n",
    "        y_pred.append('e')\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(data_test['class'], y_pred)\n",
    "print(\"Accuracy of test dataset is\", accuracy*100, \"%\")\n",
    "final_accuracy['Trival System'] = accuracy*100\n",
    "\n",
    "f_score = f1_score(data_test['class'], y_pred, pos_label='e')\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7cc0e4",
   "metadata": {},
   "source": [
    "# One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139222ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data_train.columns if data_train[col].dtype == 'object']\n",
    "for i in features:\n",
    "    print(\"Unique values of\", i, ':', data_train[i].unique())\n",
    "\n",
    "le = LabelEncoder()\n",
    "features.remove('class')\n",
    "temp_train = pd.get_dummies(data_train, columns=features)\n",
    "temp_test = pd.get_dummies(data_test, columns=features)\n",
    "temp_train['class'] = le.fit_transform(temp_train['class']) \n",
    "temp_test['class'] = le.fit_transform(temp_test['class']) \n",
    "print()\n",
    "print(\"Extra features added =\", temp_train.shape[1]-data_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb32f56d",
   "metadata": {},
   "source": [
    "### Spliting dataset into train and test set and perfoming standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7b82ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = temp_train.drop('class', axis=1)\n",
    "X_train[['cap-diameter', 'stem-height', 'stem-width']] = scaler.fit_transform(X_train[['cap-diameter', 'stem-height', 'stem-width']])\n",
    "y_train = temp_train['class']\n",
    "X_test = temp_test.drop('class', axis=1)\n",
    "X_test[['cap-diameter', 'stem-height', 'stem-width']] = scaler.fit_transform(X_test[['cap-diameter', 'stem-height', 'stem-width']])\n",
    "y_test = temp_test['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20950e7b",
   "metadata": {},
   "source": [
    "# Baseline System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30080973",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_means = X_train.groupby(y_train).mean()\n",
    "y_pred = []\n",
    "for i in range(len(X_test)):\n",
    "    distances = []\n",
    "    for j in range(len(class_means)):\n",
    "        distances.append(euclidean(X_test.iloc[i], class_means.iloc[j]))\n",
    "    \n",
    "    y_pred.append(distances.index(min(distances)))\n",
    "    \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of test dataset:\", accuracy*100, \"%\")\n",
    "final_accuracy['Baseline System'] = accuracy*100\n",
    "\n",
    "f_score = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314dc802",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2033bb3c",
   "metadata": {},
   "source": [
    "## 1) Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3553b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "log_loss_train = []\n",
    "log_loss_test = []\n",
    "for i in range(1, X_train.shape[1], 10):\n",
    "    pca = PCA(n_components=i)\n",
    "    X_pca_train = pca.fit_transform(X_train)\n",
    "    X_pca_test = pca.fit_transform(X_test)\n",
    "\n",
    "    lr = LogisticRegression(max_iter=10000)\n",
    "    lr.fit(X_pca_train, y_train)\n",
    "    y_pred_train = lr.predict(X_pca_train)\n",
    "    y_pred = lr.predict(X_pca_test)\n",
    "    \n",
    "    log_loss_train.append(log_loss(y_train, y_pred_train))\n",
    "    log_loss_test.append(log_loss(y_test, y_pred))\n",
    "    accuracy_train.append(accuracy_score(y_train, y_pred_train))\n",
    "    accuracy_test.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Best decomposition value:\", accuracy_test.index(max(accuracy_test))*10+1)\n",
    "print(\"Best accuracy of test dataset:\", max(accuracy_test)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5a315a",
   "metadata": {},
   "source": [
    "## 2) Univariate Feature Selection (Chi-Squared Contingency test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecc967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_features(X, y, k):\n",
    "    features = list(X.columns)\n",
    "    scores = []\n",
    "    for i in features:\n",
    "        score_table = pd.crosstab(X[i], y)\n",
    "        chi_val, p_val, _, _ = chi2_contingency(score_table)\n",
    "        scores.append((i, chi_val, p_val))\n",
    "        \n",
    "    scores.sort(key=lambda x: x[2])\n",
    "    top_k_features = [i[0] for i in scores[:k]]\n",
    "    \n",
    "    return top_k_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab8bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "UFS_accuracy_train = []\n",
    "UFS_accuracy_test = []\n",
    "UFS_features_list = []\n",
    "\n",
    "for i in range(1, X_train.shape[1], 10):\n",
    "    selected_features = best_features(X_train, y_train, i)\n",
    "    new_train = X_train[selected_features]\n",
    "    new_test = X_test[selected_features]\n",
    "    UFS_features_list.append(selected_features)\n",
    "    \n",
    "    lr = LogisticRegression(max_iter=10000)\n",
    "    lr.fit(new_train, y_train)\n",
    "    y_pred_train = lr.predict(new_train)\n",
    "    y_pred = lr.predict(new_test)\n",
    "\n",
    "    UFS_accuracy_train.append(accuracy_score(y_train, y_pred_train))\n",
    "    UFS_accuracy_test.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "print(\"Best number of features to select:\", len(UFS_features_list[UFS_accuracy_test.index(max(UFS_accuracy_test))]))\n",
    "print(\"-\"*50)\n",
    "print(\"Best feature set:\", UFS_features_list[UFS_accuracy_test.index(max(UFS_accuracy_test))])\n",
    "print(\"-\"*50)\n",
    "print(\"Best accuracy of test dataset:\", max(UFS_accuracy_test)*100, \"%\")\n",
    "\n",
    "plt.plot(range(1, X_train.shape[1], 10), np.array(UFS_accuracy_train)*100, label='Train dataset')\n",
    "plt.plot(range(1, X_train.shape[1], 10), np.array(UFS_accuracy_test)*100, label='Test dataset')\n",
    "plt.xlabel(\"Number of features to select\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d4ebf6",
   "metadata": {},
   "source": [
    "## 3) Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35de659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "features_list = []\n",
    "log_loss_train = []\n",
    "log_loss_test = []\n",
    "for i in range(1, X_train.shape[1], 10):\n",
    "    num_features = i\n",
    "    selected_features = []\n",
    "    lr = LogisticRegression(max_iter=10000)\n",
    "\n",
    "    for j in range(num_features):\n",
    "        score = []\n",
    "        for col in X_train.columns:\n",
    "            if col not in selected_features:\n",
    "                features = selected_features + [col]\n",
    "                lr.fit(X_train[features], y_train)\n",
    "                score.append(lr.score(X_train[features], y_train))\n",
    "        \n",
    "        selected_feature = X_train.columns[np.argmin(score)]\n",
    "        selected_features.append(selected_feature)\n",
    "    \n",
    "    new_train = X_train[selected_features]\n",
    "    features_list.append(selected_features)\n",
    "    new_train = X_train[selected_features]\n",
    "    new_test = X_test[selected_features]\n",
    "    lr.fit(new_train, y_train)\n",
    "    y_pred_train = lr.predict(new_train)\n",
    "    y_pred = lr.predict(new_test)\n",
    "\n",
    "    log_loss_train.append(log_loss(y_train, y_pred_train))\n",
    "    log_loss_test.append(log_loss(y_test, y_pred))\n",
    "    accuracy_train.append(accuracy_score(y_train, y_pred_train))\n",
    "    accuracy_test.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "print(\"Best number of features to select:\", len(features_list[accuracy_test.index(max(accuracy_test))]))\n",
    "print(\"-\"*50)\n",
    "print(\"Best feature set:\", features_list[accuracy_test.index(max(accuracy_test))])\n",
    "print(\"-\"*50)\n",
    "print(\"Best accuracy of test dataset:\", max(accuracy_test)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38785af4",
   "metadata": {},
   "source": [
    "# Models with cross validation (k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7f8c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = UFS_features_list[UFS_accuracy_test.index(max(UFS_accuracy_test))]\n",
    "splits = 10\n",
    "X_train = X_train[features]\n",
    "X_test = X_test[features]\n",
    "X, X_val, y, y_val = train_test_split(X_train, y_train, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a14f9e4",
   "metadata": {},
   "source": [
    "## 1) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3815a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits, shuffle=True)\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "acc = 0\n",
    "\n",
    "for i,j in kfold.split(X_train):\n",
    "    train_x, val_x = X_train.iloc[i], X_train.iloc[j]\n",
    "    train_y, val_y = y_train.iloc[i], y_train.iloc[j]\n",
    "    \n",
    "    lr = LogisticRegression(max_iter = 10000).fit(train_x, train_y)\n",
    "    predict_train = lr.predict(train_x)\n",
    "    train_accuracy.append(accuracy_score(predict_train, train_y))\n",
    "    \n",
    "    predict_val = lr.predict(val_x)\n",
    "    val_accuracy.append(accuracy_score(predict_val, val_y))\n",
    "    \n",
    "    if val_accuracy[-1] > acc:\n",
    "        acc = val_accuracy[-1]\n",
    "        update = lr\n",
    "        \n",
    "plt.plot(range(1, splits+1), np.array(train_accuracy)*100, label=\"Train dataset\")\n",
    "plt.plot(range(1, splits+1), np.array(val_accuracy)*100, label=\"Val dataset\")\n",
    "plt.title(\"Logistic Regression\")\n",
    "plt.xlabel('KFold Splits')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a150ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = update.predict(X_test)\n",
    "final_accuracy['LR'] = accuracy_score(y_pred, y_test)*100\n",
    "print(\"Accuracy of test dataset:\", final_accuracy['LR'], \"%\")\n",
    "\n",
    "f_score = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82af8c34",
   "metadata": {},
   "source": [
    "## 2) Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99d282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear', C=0.5).fit(X, y)\n",
    "y_pred = svm.predict(X_val)\n",
    "print(accuracy_score(y_pred, y_val))\n",
    "\n",
    "f_score = f1_score(y_val, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7250f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='rbf', C=0.5, gamma = 3).fit(X, y)\n",
    "y_pred = svm.predict(X_val)\n",
    "print(accuracy_score(y_pred, y_val))\n",
    "\n",
    "f_score = f1_score(y_val, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5289f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='rbf', C=3, gamma = 10).fit(X, y)\n",
    "y_pred = svm.predict(X_val)\n",
    "print(accuracy_score(y_pred, y_val))\n",
    "\n",
    "f_score = f1_score(y_val, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c5f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits, shuffle=True)\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "acc = 0\n",
    "\n",
    "for i,j in kfold.split(X_train):\n",
    "    train_x, val_x = X_train.iloc[i], X_train.iloc[j]\n",
    "    train_y, val_y = y_train.iloc[i], y_train.iloc[j]\n",
    "    \n",
    "    svm = SVC(kernel='rbf', C=3, gamma = 10).fit(train_x, train_y)\n",
    "    predict_train = svm.predict(train_x)\n",
    "    train_accuracy.append(accuracy_score(predict_train, train_y))\n",
    "    \n",
    "    predict_val = svm.predict(val_x)\n",
    "    val_accuracy.append(accuracy_score(predict_val, val_y))\n",
    "    \n",
    "    if val_accuracy[-1] > acc:\n",
    "        acc = val_accuracy[-1]\n",
    "        update = svm\n",
    "        \n",
    "plt.plot(range(1, splits+1), np.array(train_accuracy)*100, label=\"Train dataset\")\n",
    "plt.plot(range(1, splits+1), np.array(val_accuracy)*100, label=\"Val dataset\")\n",
    "plt.title(\"Support Vector Machine\")\n",
    "plt.xlabel('KFold Splits')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5944a0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = update.predict(X_test)\n",
    "final_accuracy['SVM'] = accuracy_score(y_pred, y_test)*100\n",
    "print(\"Accuracy of test dataset:\", final_accuracy['SVM'], \"%\")\n",
    "\n",
    "f_score = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48518430",
   "metadata": {},
   "source": [
    "## 3) Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits, shuffle=True)\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "acc = 0\n",
    "\n",
    "for i,j in kfold.split(X_train):\n",
    "    train_x, val_x = X_train.iloc[i], X_train.iloc[j]\n",
    "    train_y, val_y = y_train.iloc[i], y_train.iloc[j]\n",
    "    \n",
    "    nb = GaussianNB().fit(train_x, train_y)\n",
    "    predict_train = nb.predict(train_x)\n",
    "    train_accuracy.append(accuracy_score(predict_train, train_y))\n",
    "    \n",
    "    predict_val = nb.predict(val_x)\n",
    "    val_accuracy.append(accuracy_score(predict_val, val_y))\n",
    "    \n",
    "    if val_accuracy[-1] > acc:\n",
    "        acc = val_accuracy[-1]\n",
    "        update = nb\n",
    "\n",
    "plt.plot(range(1, splits+1), np.array(train_accuracy)*100, label=\"Train dataset\")\n",
    "plt.plot(range(1, splits+1), np.array(val_accuracy)*100, label=\"Val dataset\")\n",
    "plt.title(\"Naive Bayes\")\n",
    "plt.xlabel('KFold Splits')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aa1655",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = update.predict(X_test)\n",
    "final_accuracy['Naive Bayes'] = accuracy_score(y_pred, y_test)*100\n",
    "print(\"Accuracy of test dataset:\", final_accuracy['Naive Bayes'], \"%\")\n",
    "\n",
    "f_score = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9424c769",
   "metadata": {},
   "source": [
    "## 4) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf3eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits, shuffle=True)\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "acc = 0\n",
    "\n",
    "for i,j in kfold.split(X_train):\n",
    "    train_x, val_x = X_train.iloc[i], X_train.iloc[j]\n",
    "    train_y, val_y = y_train.iloc[i], y_train.iloc[j]\n",
    "    \n",
    "    rfm = RandomForestClassifier(n_estimators=100, random_state=0).fit(train_x, train_y)\n",
    "    predict_train = rfm.predict(train_x)\n",
    "    train_accuracy.append(accuracy_score(predict_train, train_y))\n",
    "    \n",
    "    predict_val = rfm.predict(val_x)\n",
    "    val_accuracy.append(accuracy_score(predict_val, val_y))\n",
    "    \n",
    "    if val_accuracy[-1] > acc:\n",
    "        acc = val_accuracy[-1]\n",
    "        update = rfm\n",
    "        \n",
    "plt.plot(range(1, splits+1), np.array(train_accuracy)*100, label=\"Train dataset\")\n",
    "plt.plot(range(1, splits+1), np.array(val_accuracy)*100, label=\"Val dataset\")\n",
    "plt.title(\"Random Forest\")\n",
    "plt.xlabel('KFold Splits')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f0cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = update.predict(X_test)\n",
    "final_accuracy['Random Forest'] = accuracy_score(y_pred, y_test)*100\n",
    "print(\"Accuracy of test dataset:\", final_accuracy['Random Forest'], \"%\")\n",
    "\n",
    "f_score = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e61392b",
   "metadata": {},
   "source": [
    "## 5) XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24daba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X, label=y)\n",
    "params = {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 3, 'eta': 0.1, 'gamma': 1, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
    "num_rounds = 100\n",
    "\n",
    "xgb_model = xgb.train(params, dtrain, num_rounds)\n",
    "dtest = xgb.DMatrix(X_val, label=y_val)\n",
    "predict = xgb_model.predict(dtest)\n",
    "y_pred = [round(y) for y in predict]\n",
    "print(accuracy_score(y_pred, y_val))\n",
    "\n",
    "f_score = f1_score(y_val, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cb2679",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X, label=y)\n",
    "params = {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 8, 'eta': 0.5, 'gamma': 3, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
    "num_rounds = 100\n",
    "\n",
    "xgb_model = xgb.train(params, dtrain, num_rounds)\n",
    "dtest = xgb.DMatrix(X_val, label=y_val)\n",
    "predict = xgb_model.predict(dtest)\n",
    "y_pred = [round(y) for y in predict]\n",
    "print(accuracy_score(y_pred, y_val))\n",
    "\n",
    "f_score = f1_score(y_val, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00451cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X, label=y)\n",
    "params = {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 15, 'eta': 0.8, 'gamma': 7, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
    "num_rounds = 100\n",
    "\n",
    "xgb_model = xgb.train(params, dtrain, num_rounds)\n",
    "dtest = xgb.DMatrix(X_val, label=y_val)\n",
    "predict = xgb_model.predict(dtest)\n",
    "y_pred = [round(y) for y in predict]\n",
    "print(accuracy_score(y_pred, y_val))\n",
    "\n",
    "f_score = f1_score(y_val, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62574a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits, shuffle=True)\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "acc = 0\n",
    "\n",
    "for i,j in kfold.split(X_train):\n",
    "    train_x, val_x = X_train.iloc[i], X_train.iloc[j]\n",
    "    train_y, val_y = y_train.iloc[i], y_train.iloc[j]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "    dval = xgb.DMatrix(val_x, label=val_y)\n",
    "    params = {'objective': 'binary:logistic', 'eval_metric': 'error', 'max_depth': 3, 'eta': 0.1, 'gamma': 1, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
    "    num_rounds = 100\n",
    "    \n",
    "    xgb_model = xgb.train(params, dtrain, num_rounds)\n",
    "    y_pred_train = xgb_model.predict(dtrain)\n",
    "    y_pred_train_binary = [round(y) for y in y_pred_train]\n",
    "    train_accuracy.append(accuracy_score(y_pred_train_binary, train_y))\n",
    "    \n",
    "    y_pred_test = xgb_model.predict(dval)\n",
    "    y_pred_test_binary = [round(y) for y in y_pred_test]\n",
    "    val_accuracy.append(accuracy_score(y_pred_test_binary, val_y))\n",
    "    \n",
    "    if val_accuracy[-1] > acc:\n",
    "        acc = val_accuracy[-1]\n",
    "        update = xgb_model\n",
    "        \n",
    "plt.plot(range(1, splits+1), np.array(train_accuracy)*100, label=\"Train dataset\")\n",
    "plt.plot(range(1, splits+1), np.array(val_accuracy)*100, label=\"Val dataset\")\n",
    "plt.title(\"XgBoost\")\n",
    "plt.xlabel('KFold Splits')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2486b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "predict = update.predict(dtest)\n",
    "y_pred = [round(y) for y in predict]\n",
    "final_accuracy['XgBoost'] = accuracy_score(y_pred, y_test)*100\n",
    "print(\"Accuracy of test dataset:\", final_accuracy['XgBoost'], \"%\")\n",
    "\n",
    "f_score = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b75b4f",
   "metadata": {},
   "source": [
    "## 6) Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e09dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', alpha=0.0001, learning_rate_init=0.001, max_iter=10000, early_stopping=False) \n",
    "mlp.fit(X, y)\n",
    "\n",
    "y_pred = mlp.predict(X_val)\n",
    "print(accuracy_score(y_pred, y_val))\n",
    "\n",
    "f_score = f1_score(y_val, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895381ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='logistic', solver='sgd', alpha=0.001, learning_rate_init=0.01, max_iter=10000, early_stopping=False) \n",
    "mlp.fit(X, y)\n",
    "\n",
    "y_pred = mlp.predict(X_val)\n",
    "print(accuracy_score(y_pred, y_val))\n",
    "\n",
    "f_score = f1_score(y_val, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff7b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='tanh', solver='adam', alpha=0.01, learning_rate_init=0.5, max_iter=10000, early_stopping=False) \n",
    "mlp.fit(X, y)\n",
    "\n",
    "y_pred = mlp.predict(X_val)\n",
    "print(accuracy_score(y_pred, y_val))\n",
    "\n",
    "f_score = f1_score(y_val, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a2dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits, shuffle=True)\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "acc = 0\n",
    "\n",
    "for i,j in kfold.split(X_train):\n",
    "    train_x, val_x = X_train.iloc[i], X_train.iloc[j]\n",
    "    train_y, val_y = y_train.iloc[i], y_train.iloc[j]\n",
    "    \n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', alpha=0.0001, learning_rate_init=0.001, max_iter=200, early_stopping=False) \n",
    "    mlp.fit(train_x, train_y)\n",
    "    predict_train = mlp.predict(train_x)\n",
    "    train_accuracy.append(accuracy_score(predict_train, train_y))\n",
    "    \n",
    "    predict_val = mlp.predict(val_x)\n",
    "    val_accuracy.append(accuracy_score(predict_val, val_y))\n",
    "    \n",
    "    if val_accuracy[-1] > acc:\n",
    "        acc = val_accuracy[-1]\n",
    "        update = mlp\n",
    "        \n",
    "plt.plot(range(1, splits+1), np.array(train_accuracy)*100, label=\"Train dataset\")\n",
    "plt.plot(range(1, splits+1), np.array(val_accuracy)*100, label=\"Val dataset\")\n",
    "plt.title(\"Multi Layer Perceptron\")\n",
    "plt.xlabel('KFold Splits')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f16499",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = update.predict(X_test)\n",
    "final_accuracy['MLP'] = accuracy_score(y_pred, y_test)*100\n",
    "print(\"Accuracy of test dataset:\", final_accuracy['MLP'], \"%\")\n",
    "\n",
    "f_score = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf90493",
   "metadata": {},
   "source": [
    "# Final accuracies for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c986d336",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = list(final_accuracy.keys())\n",
    "models = list(final_accuracy.values())\n",
    "plt.xticks(rotation = 45, ha = 'right')\n",
    "bars = plt.bar(accuracy, models)\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, height, '{:.3f}'.format(height), ha = 'center', va = 'bottom')\n",
    "plt.title(\"Model Accuracies for One-Hot Encoding Feature Engineering\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1632e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = max(final_accuracy, key=final_accuracy.get)\n",
    "best_accuracy = final_accuracy[best_model]\n",
    "print(f\"Best model is {best_model} with accuracy {best_accuracy} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36934e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_accuracy={'Trivial System':50.6524, 'Baseline System': 62.8560, 'LR': 77.757, 'SVM': 98.760, 'Naive Bayes': 70.334, 'Random Forest':99.907, 'XgBoost': 80.265, 'MLP': 99.863}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec113ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
